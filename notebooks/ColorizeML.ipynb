{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import color, io\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToLab(image, label):\n",
    "    lab = color.rgb2lab(label)\n",
    "    X_batch = lab[:,:,0]\n",
    "    Y_batch = lab[:,:,1:]\n",
    "    return X_batch.reshape(X_batch.shape+(1,)), Y_batch\n",
    "\n",
    "\n",
    "def _parse_function(filename):\n",
    "    image = tf.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize_images(image, [256, 256], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    label = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    label = tf.divide(label, 255.0)\n",
    "    \n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "file_paths = map((lambda x: \"../data/\" + x), os.listdir(\"../data/\"))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "dataset = dataset.map(_parse_function)\n",
    "dataset = dataset.map(lambda image, label: \n",
    "    tuple(tf.py_func(\n",
    "        convertToLab, [image, label], [tf.double, tf.double]\n",
    "    ))\n",
    ")\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_paths = map((lambda x: \"../data/\" + x), os.listdir(\"../data/\"))\n",
    "#\n",
    "#all_images = ops.convert_to_tensor(file_paths, dtype=dtypes.string)\n",
    "#\n",
    "#train_input_queue = tf.train.slice_input_producer(\n",
    "#                                    [all_images, all_images],\n",
    "#                                    shuffle=False)\n",
    "#\n",
    "#\n",
    "#file_content = tf.read_file(train_input_queue[0])\n",
    "#train_image = tf.image.decode_jpeg(file_content, channels=3)\n",
    "#train_image = tf.image.resize_images(train_image, [256, 256], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "#train_image = tf.image.rgb_to_grayscale(train_image)\n",
    "#train_image = tf.image.convert_image_dtype(train_image, tf.float32)\n",
    "#\n",
    "#label_content = tf.read_file(train_input_queue[1])\n",
    "#train_label = tf.image.decode_jpeg(file_content, channels=3)\n",
    "#train_label = tf.image.resize_images(train_label, [256, 256], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "#train_label = tf.image.convert_image_dtype(train_label, tf.float32)\n",
    "#train_label = tf.divide(train_label, 255.0)\n",
    "#\n",
    "#\n",
    "#                    \n",
    "## collect batches of images before processing\n",
    "#train_image_batch, train_label_batch = tf.train.batch(\n",
    "#    [train_image, train_label],\n",
    "#    batch_size=batch_size\n",
    "#    #,num_threads=1\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(num, imgs):\n",
    "    # Start populating the filename queue.\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(num): #length of your filename list\n",
    "        image = imgs.eval() \n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareImages(imgs):\n",
    "    sz_imgs = tf.image.resize_images(imgs, [256, 256], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    bw_imgs = tf.image.rgb_to_grayscale(sz_imgs)\n",
    "    \n",
    "    return sz_imgs, bw_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageLabGenerator(size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2DRelu(X, W, B, strides, padding):\n",
    "    # strides: [batch_step, height_step, width_step, channel_step] \n",
    "    return tf.nn.relu(tf.nn.conv2d(X, W, strides=strides, padding=padding) + B)\n",
    "\n",
    "def conv2DTanh(X, W, B, strides, padding):\n",
    "    # strides: [batch_step, height_step, width_step, channel_step] \n",
    "    return tf.nn.tanh(tf.nn.conv2d(X, W, strides=strides, padding=padding) + B)\n",
    "\n",
    "def weight(width, height, input_channels, output_channels):\n",
    "    # [width, height, input channel, output channel]\n",
    "    return tf.Variable(tf.truncated_normal([width, height, input_channels, output_channels], stddev=0.1))\n",
    "\n",
    "def bias(outputChannels):\n",
    "    return tf.Variable(tf.zeros([outputChannels])) # bias for each output channel.\n",
    "\n",
    "def upSampling2D(X, height, width):\n",
    "    return tf.image.resize_images(X, [height, width], tf.image.ResizeMethod.NEAREST_NEIGHBOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input images x will consist of a 2d tensor of floating point numbers.\n",
    "#X = tf.placeholder(tf.float32, shape=[None, [256, 256, 1]]) # 256 x 256\n",
    "# The target output y_ will also consist of a 2d tensor, where each row is \n",
    "# a one-hot 2-dimensional vector indicating a b values.\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 256, 256, 2])\n",
    "\n",
    "# Input Layer\n",
    "X = tf.placeholder(tf.float32, shape=[None, 256, 256, 1]) # 256 x 256\n",
    "\n",
    "# Conv layer 1 \n",
    "W1 = weight(5, 5, 1, 64)\n",
    "B1 = bias(64)\n",
    "Y1 = conv2DRelu(X, W1, B1, [1,1,1,1], 'SAME')\n",
    "\n",
    "# Conv layer 2\n",
    "W2 = weight(5, 5, 64, 64)\n",
    "B2 = bias(64)\n",
    "Y2 = conv2DRelu(Y1, W2, B2, [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "# Conv layer 3\n",
    "W3 = weight(5, 5, 64, 128)\n",
    "B3 = bias(128)\n",
    "Y3 = conv2DRelu(Y2, W3, B3, [1, 1, 1, 1], 'SAME')\n",
    "\n",
    "# Conv layer 4\n",
    "W4 = weight(5, 5, 128, 128)\n",
    "B4 = bias(128)\n",
    "Y4 = conv2DRelu(Y3, W4, B4, [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "# Conv layer 5\n",
    "W5 = weight(5, 5, 128, 256)\n",
    "B5 = bias(256)\n",
    "Y5 = conv2DRelu(Y4, W5, B5, [1, 1, 1, 1], 'SAME')\n",
    "\n",
    "# Conv layer 6\n",
    "W6 = weight(5, 5, 256, 256)\n",
    "B6 = bias(256)\n",
    "Y6 = conv2DRelu(Y5, W6, B6, [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "# Conv layer 7\n",
    "W7 = weight(5, 5, 256, 512)\n",
    "B7 = bias(512)\n",
    "Y7 = conv2DRelu(Y6, W7, B7, [1, 1, 1, 1], 'SAME')\n",
    "\n",
    "# Conv layer 8\n",
    "W8 = weight(5, 5, 512, 256)\n",
    "B8 = bias(256)\n",
    "Y8 = conv2DRelu(Y7, W8, B8, [1, 1, 1, 1], 'SAME')\n",
    "\n",
    "# Conv layer 9\n",
    "W9 = weight(5, 5, 256, 128)\n",
    "B9 = bias(128)\n",
    "Y9 = conv2DRelu(Y8, W9, B9, [1, 1, 1, 1], 'SAME')\n",
    "\n",
    "# Up sampling layer 1\n",
    "Y10 = upSampling2D(Y9, 64, 64)\n",
    "\n",
    "# Conv layer 10\n",
    "W11 = weight(5, 5, 128, 64)\n",
    "B11 = bias(64)\n",
    "Y11 = conv2DRelu(Y10, W11, B11, [1, 1, 1, 1], 'SAME')\n",
    "\n",
    "# Up sampling layer 2\n",
    "Y12 = upSampling2D(Y11, 128, 128)\n",
    "\n",
    "# Conv layer 11\n",
    "W13 = weight(5, 5, 64, 32)\n",
    "B13 = bias(32)\n",
    "Y13 = conv2DRelu(Y12, W13, B13, [1, 1, 1, 1], 'SAME')\n",
    "\n",
    "# Conv layer 12\n",
    "W14 = weight(5, 5, 32, 2)\n",
    "B14 = bias(2)\n",
    "Y14 = conv2DTanh(Y13, W14, B14, [1, 1, 1, 1], 'SAME')\n",
    "\n",
    "# Up sampling layer 3\n",
    "Y15 = upSampling2D(Y14, 256, 256)\n",
    "\n",
    "# Define the loss function \n",
    "loss = tf.reduce_mean(tf.squared_difference(Y15, Y_)) \n",
    "\n",
    "# Define an optimizer\n",
    "train_step = tf.train.AdamOptimizer(0.005).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(i, batch_X, batch_Y):\n",
    "    print batch_X\n",
    "    print batch_Y\n",
    "    print \"\\r\", i,\n",
    "    sess.run(train_step, feed_dict={X: batch_X, Y_: batch_Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "  \n",
    "    # initialize the variables\n",
    "    sess.run(init)\n",
    "\n",
    "    # initialize the queue threads to start to shovel data\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    print \"from the train set:\"\n",
    "    images, labels = iterator.get_next()\n",
    "    for i in range(12):\n",
    "        print sess.run(training_step(i, images.eval(), labels.eval()))\n",
    "\n",
    "    # stop our queue threads and properly close the session\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
