{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import color, io\n",
    "from skimage.io import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.local/share/jupyter/runtime/kernel-afcf7348-7111-4ffa-a370-3cf3c56953fd.json/0.0.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "model_version = '0.0.1'\n",
    "\n",
    "export_path_base = sys.argv[-1]\n",
    "export_path = os.path.join(\n",
    "      tf.compat.as_bytes(export_path_base),\n",
    "      tf.compat.as_bytes(model_version))\n",
    "print export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToLab(image):\n",
    "    lab = color.rgb2lab(image)\n",
    "    X_batch = lab[:,:,0]\n",
    "    Y_batch = lab[:,:,1:] / 128\n",
    "    return X_batch.reshape(X_batch.shape+(1,)), Y_batch\n",
    "\n",
    "def parseImage(filename):\n",
    "    image = tf.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize_images(image, [400, 400], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_test_paths = ['woman.jpg']\n",
    "file_test_paths = map((lambda x: \"../train4/\" + x), os.listdir(\"../train4/\"))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(file_test_paths)\n",
    "dataset = dataset.map(parseImage)\n",
    "dataset = dataset.map(lambda image:\n",
    "    tuple(tf.py_func(\n",
    "        convertToLab, [image], [tf.double, tf.double]\n",
    "    ))\n",
    ")\n",
    "dataset = dataset.batch(1)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2DRelu(X, W, B, strides, padding):\n",
    "    # strides: [batch_step, height_step, width_step, channel_step]\n",
    "    return tf.nn.relu(tf.nn.conv2d(X, W, strides=strides, padding=padding) + B)\n",
    "\n",
    "def conv2DTanh(X, W, B, strides, padding):\n",
    "    # strides: [batch_step, height_step, width_step, channel_step]\n",
    "    return tf.nn.tanh(tf.nn.conv2d(X, W, strides=strides, padding=padding) + B)\n",
    "\n",
    "def weight(width, height, input_channels, output_channels):\n",
    "    # [width, height, input channel, output channel]\n",
    "    return tf.Variable(tf.truncated_normal([width, height, input_channels, output_channels], stddev=0.1))\n",
    "\n",
    "def bias(outputChannels):\n",
    "    return tf.Variable(tf.zeros([outputChannels])) # bias for each output channel.\n",
    "\n",
    "def upSampling2D(X, height, width):\n",
    "    return tf.image.resize_images(X, [height, width], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "def upSampleToOriginalSize(X, size):\n",
    "    return tf.image.resize_images(X, size, tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "def Conv2D(X, input_channels, output_channels, scan=3, activation='relu', padding='SAME', strides=1):\n",
    "    W = weight(scan, scan, input_channels, output_channels)\n",
    "    B = bias(output_channels)\n",
    "    if activation == 'relu':\n",
    "        return conv2DRelu(X, W, B, [1,strides,strides,1], padding)\n",
    "    else:\n",
    "        return conv2DTanh(X, W, B, [1,strides,strides,1], padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ = tf.placeholder(tf.float32, shape=[None, 400, 400, 2]) # True Value\n",
    "X = tf.placeholder(tf.float32, shape=[None, 400, 400, 1]) # Input\n",
    "\n",
    "Y1 = Conv2D(X, 1, 8, 3, 'relu', 'SAME', 2)\n",
    "Y2 = Conv2D(Y1, 8, 8, 3, 'relu', 'SAME', 1)\n",
    "Y3 = Conv2D(Y2, 8, 16, 3, 'relu', 'SAME', 1)\n",
    "Y4 = Conv2D(Y3, 16, 16, 3, 'relu', 'SAME', 2)\n",
    "Y5 = Conv2D(Y4, 16, 32, 3, 'relu', 'SAME', 1)\n",
    "Y6 = Conv2D(Y5, 32, 32, 3, 'relu', 'SAME', 2)\n",
    "Y7 = upSampling2D(Y6, 100, 100)\n",
    "Y8 = Conv2D(Y7, 32, 32, 3, 'relu', 'SAME', 1)\n",
    "Y9 = upSampling2D(Y8, 200, 200)\n",
    "Y10 = Conv2D(Y9, 32, 16, 3, 'relu', 'SAME', 1)\n",
    "Y11 = upSampling2D(Y10, 400, 400)\n",
    "Y12 = Conv2D(Y11, 16, 2, 3, 'tanh', 'SAME', 1)\n",
    "\n",
    "# Define the loss function\n",
    "loss = tf.reduce_mean(tf.squared_difference(Y12, Y_), 1)\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from the train set:\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n",
      "Step: 25\n",
      "Step: 26\n",
      "Step: 27\n",
      "Step: 28\n",
      "Step: 29\n",
      "Step: 30\n",
      "Step: 31\n",
      "Step: 32\n",
      "Step: 33\n",
      "Step: 34\n",
      "Step: 35\n",
      "Step: 36\n",
      "Step: 37\n",
      "Step: 38\n",
      "Step: 39\n",
      "Step: 40\n",
      "Step: 41\n",
      "Step: 42\n",
      "Step: 43\n",
      "Step: 44\n",
      "Step: 45\n",
      "Step: 46\n",
      "Step: 47\n",
      "Step: 48\n",
      "Step: 49\n",
      "Step: 50\n",
      "Step: 51\n",
      "Step: 52\n",
      "Step: 53\n",
      "Step: 54\n",
      "Step: 55\n",
      "Step: 56\n",
      "Step: 57\n",
      "Step: 58\n",
      "Step: 59\n",
      "Step: 60\n",
      "Step: 61\n",
      "Step: 62\n",
      "Step: 63\n",
      "Step: 64\n",
      "Step: 65\n",
      "Step: 66\n",
      "Step: 67\n",
      "Step: 68\n",
      "Step: 69\n",
      "Step: 70\n",
      "Step: 71\n",
      "Step: 72\n",
      "Step: 73\n",
      "Step: 74\n",
      "Step: 75\n",
      "Step: 76\n",
      "Step: 77\n",
      "Step: 78\n",
      "Step: 79\n",
      "Step: 80\n",
      "Step: 81\n",
      "Step: 82\n",
      "Step: 83\n",
      "Step: 84\n",
      "Step: 85\n",
      "Step: 86\n",
      "Step: 87\n",
      "Step: 88\n",
      "Step: 89\n",
      "Step: 90\n",
      "Step: 91\n",
      "Step: 92\n",
      "Step: 93\n",
      "Step: 94\n",
      "Step: 95\n",
      "Step: 96\n",
      "Step: 97\n",
      "Step: 98\n",
      "Step: 99\n",
      "Step: 100\n",
      "Step: 101\n",
      "Step: 102\n",
      "Step: 103\n",
      "Step: 104\n",
      "Step: 105\n",
      "Step: 106\n",
      "Step: 107\n",
      "Step: 108\n",
      "Step: 109\n",
      "Step: 110\n",
      "Step: 111\n",
      "Step: 112\n",
      "Step: 113\n",
      "Step: 114\n",
      "Step: 115\n",
      "Step: 116\n",
      "Step: 117\n",
      "Step: 118\n",
      "Step: 119\n",
      "Step: 120\n",
      "Step: 121\n",
      "Step: 122\n",
      "Step: 123\n",
      "Step: 124\n",
      "Step: 125\n",
      "Step: 126\n",
      "Step: 127\n",
      "Step: 128\n",
      "Step: 129\n",
      "Step: 130\n",
      "Step: 131\n",
      "Step: 132\n",
      "Step: 133\n",
      "Step: 134\n",
      "Step: 135\n",
      "Step: 136\n",
      "Step: 137\n",
      "Step: 138\n",
      "Step: 139\n",
      "Step: 140\n",
      "Step: 141\n",
      "Step: 142\n",
      "Step: 143\n",
      "Step: 144\n",
      "Step: 145\n",
      "Step: 146\n",
      "Step: 147\n",
      "Step: 148\n",
      "Step: 149\n",
      "Step: 150\n",
      "Step: 151\n",
      "Step: 152\n",
      "Step: 153\n",
      "Step: 154\n",
      "Step: 155\n",
      "Step: 156\n",
      "Step: 157\n",
      "Step: 158\n",
      "Step: 159\n",
      "Step: 160\n",
      "Step: 161\n",
      "Step: 162\n",
      "Step: 163\n",
      "Step: 164\n",
      "Step: 165\n",
      "Step: 166\n",
      "Step: 167\n",
      "Step: 168\n",
      "Step: 169\n",
      "Step: 170\n",
      "Step: 171\n",
      "Step: 172\n",
      "Step: 173\n",
      "Step: 174\n",
      "Step: 175\n",
      "Step: 176\n",
      "Step: 177\n",
      "Step: 178\n",
      "Step: 179\n",
      "Step: 180\n",
      "Step: 181\n",
      "Step: 182\n",
      "Step: 183\n",
      "Step: 184\n",
      "Step: 185\n",
      "Step: 186\n",
      "Step: 187\n",
      "Step: 188\n",
      "Step: 189\n",
      "Step: 190\n",
      "Step: 191\n",
      "Step: 192\n",
      "Step: 193\n",
      "Step: 194\n",
      "Step: 195\n",
      "Step: 196\n",
      "Step: 197\n",
      "Step: 198\n",
      "Step: 199\n",
      "Step: 200\n",
      "Step: 201\n",
      "Step: 202\n",
      "Step: 203\n",
      "Step: 204\n",
      "Step: 205\n",
      "Step: 206\n",
      "Step: 207\n",
      "Step: 208\n",
      "Step: 209\n",
      "Step: 210\n",
      "Step: 211\n",
      "Step: 212\n",
      "Step: 213\n",
      "Step: 214\n",
      "Step: 215\n",
      "Step: 216\n",
      "Step: 217\n",
      "Step: 218\n",
      "Step: 219\n",
      "Step: 220\n",
      "Step: 221\n",
      "Step: 222\n",
      "Step: 223\n",
      "Step: 224\n",
      "Step: 225\n",
      "Step: 226\n",
      "Step: 227\n",
      "Step: 228\n",
      "Step: 229\n",
      "Step: 230\n",
      "Step: 231\n",
      "Step: 232\n",
      "Step: 233\n",
      "Step: 234\n",
      "Step: 235\n",
      "Step: 236\n",
      "Step: 237\n",
      "Step: 238\n",
      "Step: 239\n",
      "Step: 240\n",
      "Step: 241\n",
      "Step: 242\n",
      "Step: 243\n",
      "Step: 244\n",
      "Step: 245\n",
      "Step: 246\n",
      "Step: 247\n",
      "Step: 248\n",
      "Step: 249\n",
      "Step: 250\n",
      "Step: 251\n",
      "Step: 252\n",
      "Step: 253\n",
      "Step: 254\n",
      "Step: 255\n",
      "Step: 256\n",
      "Step: 257\n",
      "Step: 258\n",
      "Step: 259\n",
      "Step: 260\n",
      "Step: 261\n",
      "Step: 262\n",
      "Step: 263\n",
      "Step: 264\n",
      "Step: 265\n",
      "Step: 266\n",
      "Step: 267\n",
      "Step: 268\n",
      "Step: 269\n",
      "Step: 270\n",
      "Step: 271\n",
      "Step: 272\n",
      "Step: 273\n",
      "Step: 274\n",
      "Step: 275\n",
      "Step: 276\n",
      "Step: 277\n",
      "Step: 278\n",
      "Step: 279\n",
      "Step: 280\n",
      "Step: 281\n",
      "Step: 282\n",
      "Step: 283\n",
      "Step: 284\n",
      "Step: 285\n",
      "Step: 286\n",
      "Step: 287\n",
      "Step: 288\n",
      "Step: 289\n",
      "Step: 290\n",
      "Step: 291\n",
      "Step: 292\n",
      "Step: 293\n",
      "Step: 294\n",
      "Step: 295\n",
      "Step: 296\n",
      "Step: 297\n",
      "Step: 298\n",
      "Step: 299\n",
      "Step: 300\n",
      "Step: 301\n",
      "Step: 302\n",
      "Step: 303\n",
      "Step: 304\n",
      "Step: 305\n",
      "Step: 306\n",
      "Step: 307\n",
      "Step: 308\n",
      "Step: 309\n",
      "Step: 310\n",
      "Step: 311\n",
      "Step: 312\n",
      "Step: 313\n",
      "Step: 314\n",
      "Step: 315\n",
      "Step: 316\n",
      "Step: 317\n",
      "Step: 318\n",
      "Step: 319\n",
      "Step: 320\n",
      "Step: 321\n",
      "Step: 322\n",
      "Step: 323\n",
      "Step: 324\n",
      "Step: 325\n",
      "Step: 326\n",
      "Step: 327\n",
      "Step: 328\n",
      "Step: 329\n",
      "Step: 330\n",
      "Step: 331\n",
      "Step: 332\n",
      "Step: 333\n",
      "Step: 334\n",
      "Step: 335\n",
      "Step: 336\n",
      "Step: 337\n",
      "Step: 338\n",
      "Step: 339\n",
      "Step: 340\n",
      "Step: 341\n",
      "Step: 342\n",
      "Step: 343\n",
      "Step: 344\n",
      "Step: 345\n",
      "Step: 346\n",
      "Step: 347\n",
      "Step: 348\n",
      "Step: 349\n",
      "Step: 350\n",
      "Step: 351\n",
      "Step: 352\n",
      "Step: 353\n",
      "Step: 354\n",
      "Step: 355\n",
      "Step: 356\n",
      "Step: 357\n",
      "Step: 358\n",
      "Step: 359\n",
      "Step: 360\n",
      "Step: 361\n",
      "Step: 362\n",
      "Step: 363\n",
      "Step: 364\n",
      "Step: 365\n",
      "Step: 366\n",
      "Step: 367\n",
      "Step: 368\n",
      "Step: 369\n",
      "Step: 370\n",
      "Step: 371\n",
      "Step: 372\n",
      "Step: 373\n",
      "Step: 374\n",
      "Step: 375\n",
      "Step: 376\n",
      "Step: 377\n",
      "Step: 378\n",
      "Step: 379\n",
      "Step: 380\n",
      "Step: 381\n",
      "Step: 382\n",
      "Step: 383\n",
      "Step: 384\n",
      "Step: 385\n",
      "Step: 386\n",
      "Step: 387\n",
      "Step: 388\n",
      "Step: 389\n",
      "Step: 390\n",
      "Step: 391\n",
      "Step: 392\n",
      "End of training dataset.\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "next_element = iterator.get_next()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize the variables\n",
    "    sess.run(init)\n",
    "\n",
    "    # initialize the queue threads to start to shovel data\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    print(\"from the train set:\")\n",
    "    # images, labels = iterator.get_next()\n",
    "    step = 0\n",
    "    while True:\n",
    "\n",
    "        try:\n",
    "            elem = sess.run(next_element)\n",
    "            print \"Step:\", step\n",
    "            for i in range(1):\n",
    "                # print(\"Round:\", i)\n",
    "                _, luss = sess.run([optimizer, loss], feed_dict={\n",
    "                    X: elem[0], Y_: elem[1]\n",
    "                })\n",
    "                # print(\"Loss:\", luss[0][0][0])\n",
    "            step += 1\n",
    "            \n",
    "            if step == 2000:\n",
    "                saver.save(sess, './model/' + 'model.ckpt', global_step=step + 1)\n",
    "                print \"End of training dataset.\"\n",
    "                break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            saver.save(sess, './model/' + 'model.ckpt', global_step=step + 1)\n",
    "            print \"End of training dataset.\"\n",
    "            break\n",
    "\n",
    "    # stop our queue threads and properly close the session\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-394\n",
      "PRINTING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "file_test_paths = ['woman.jpg']\n",
    "\n",
    "testDataset = tf.data.Dataset.from_tensor_slices(file_test_paths)\n",
    "testDataset = testDataset.map(parseImage)\n",
    "testDataset = testDataset.map(lambda image:\n",
    "    tuple(tf.py_func(\n",
    "        convertToLab, [image], [tf.double, tf.double]\n",
    "    ))\n",
    ")\n",
    "testDataset = testDataset.batch(1)\n",
    "\n",
    "testIterator = testDataset.make_one_shot_iterator()\n",
    "\n",
    "\n",
    "def plotImage(image):\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "next_element = testIterator.get_next()\n",
    "with tf.Session() as session:\n",
    "    elem = session.run(next_element)\n",
    "    ckpt = tf.train.get_checkpoint_state('./model/')\n",
    "    saver.restore(session, ckpt.model_checkpoint_path)\n",
    "    feed_dict = {X: elem[0], Y_: elem[1]}\n",
    "    _, ab = session.run([optimizer, Y12], feed_dict)\n",
    "\n",
    "    # Colorize output\n",
    "    ab = ab * 128\n",
    "\n",
    "    cur = np.zeros((400, 400, 3))\n",
    "    cur[:, :, 0] = elem[0][0][:, :, 0]\n",
    "    cur[:, :, 1:] = ab[0]\n",
    "    print(\"PRINTING\")\n",
    "    imsave(\"notebook_test.jpg\", color.lab2rgb(cur))\n",
    "    imsave(\"okkar_gray_version.png\", color.rgb2gray(color.lab2rgb(cur)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
