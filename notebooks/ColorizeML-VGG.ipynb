{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy\n",
    "from skimage import color, io\n",
    "from skimage.io import imsave\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data():\n",
    "    data = numpy.load(\"../vgg/vgg_model.npy\")\n",
    "    return data[()]\n",
    "\n",
    "def weight(width, height, input_channels, output_channels, variable_name):\n",
    "    # [width, height, input channel, output channel]\n",
    "    return tf.get_variable(variable_name, initializer=tf.truncated_normal([width, height, input_channels, output_channels], stddev=0.02))\n",
    "\n",
    "def bias(output_channels, variable_name):\n",
    "    return tf.get_variable(variable_name, initializer=tf.constant(0.0, shape=[output_channels]))\n",
    "\n",
    "def maxPool(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "def conv2dTranspose(X, W, B, output_shape, stride=2):\n",
    "    # Lesa Ã¾etta: http://www.matthewzeiler.com/wp-content/uploads/2017/07/cvpr2010.pdf\n",
    "    conv2d = tf.nn.conv2d_transpose(X, W, output_shape, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "    return tf.nn.bias_add(conv2d, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateVGGLayers(input_layer):\n",
    "    vgg_model = get_model_data()\n",
    "    vgg_network = {}\n",
    "\n",
    "    def vggVariable(values, name):\n",
    "        # Populate tensor with values\n",
    "        return tf.get_variable(\n",
    "            name=name, \n",
    "            initializer=tf.constant_initializer(values, dtype=tf.float32), \n",
    "            shape=values.shape\n",
    "        )\n",
    "\n",
    "    def mat2tf(kernels):\n",
    "        # matconvnet: [width, height, in_channels, out_channels]\n",
    "        # tensorflow: [height, width, in_channels, out_channels]\n",
    "        return numpy.transpose(kernels, (1, 0, 2, 3))\n",
    "\n",
    "    def vggConv(name, X):\n",
    "        weight = mat2tf(vgg_model[name]['kernels'])\n",
    "        bias = vgg_model[name]['bias'].reshape(-1) # flatten\n",
    "\n",
    "        weight = vggVariable(weight, \"vgg/\" + name + \"/weight\")\n",
    "        bias = vggVariable(bias, \"vgg/\" + name + \"/bias\")\n",
    "\n",
    "        X = tf.nn.conv2d(X, weight, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        return tf.nn.bias_add(X, bias)\n",
    "\n",
    "    def vggRelu(name, X):\n",
    "        return tf.nn.relu(X, name=\"vgg/\" + name + \"/relu\")\n",
    "    \n",
    "    def vggPool(X):\n",
    "        return tf.nn.avg_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "    # Hidden layer 1\n",
    "    vgg_network['conv1_2'] = vggConv('conv1_2', input_layer)\n",
    "    vgg_network['relu1_2'] = vggRelu('relu1_2', vgg_network['conv1_2'])\n",
    "    vgg_network['pool1'] = vggPool(vgg_network['relu1_2'])\n",
    "\n",
    "    # Hidden layer 2\n",
    "    vgg_network['conv2_1'] = vggConv('conv2_1', vgg_network['pool1'])\n",
    "    vgg_network['relu2_1'] = vggRelu('relu2_1', vgg_network['conv2_1'])\n",
    "    vgg_network['conv2_2'] = vggConv('conv2_2', vgg_network['relu2_1'])\n",
    "    vgg_network['relu2_2'] = vggRelu('relu2_2', vgg_network['conv2_2'])\n",
    "    vgg_network['pool2'] = vggPool(vgg_network['relu2_2'])\n",
    "\n",
    "    # Hidden layer 3\n",
    "    vgg_network['conv3_1'] = vggConv('conv3_1', vgg_network['pool2'])\n",
    "    vgg_network['relu3_1'] = vggRelu('relu3_1', vgg_network['conv3_1'])\n",
    "    vgg_network['conv3_2'] = vggConv('conv3_2', vgg_network['relu3_1'])\n",
    "    vgg_network['relu3_2'] = vggRelu('relu3_2', vgg_network['conv3_2'])\n",
    "    vgg_network['conv3_3'] = vggConv('conv3_3', vgg_network['relu3_2'])\n",
    "    vgg_network['relu3_3'] = vggRelu('relu3_3', vgg_network['conv3_3'])\n",
    "    vgg_network['conv3_4'] = vggConv('conv3_4', vgg_network['relu3_3'])\n",
    "    vgg_network['relu3_4'] = vggRelu('relu3_4', vgg_network['conv3_4'])\n",
    "    vgg_network['pool3'] = vggPool(vgg_network['relu3_4'])\n",
    "\n",
    "    # Hidden layer 4\n",
    "    vgg_network['conv4_1'] = vggConv('conv4_1', vgg_network['pool3'])\n",
    "    vgg_network['relu4_1'] = vggRelu('relu4_1', vgg_network['conv4_1'])\n",
    "    vgg_network['conv4_2'] = vggConv('conv4_2', vgg_network['relu4_1'])\n",
    "    vgg_network['relu4_2'] = vggRelu('relu4_2', vgg_network['conv4_2'])\n",
    "    vgg_network['conv4_3'] = vggConv('conv4_3', vgg_network['relu4_2'])\n",
    "    vgg_network['relu4_3'] = vggRelu('relu4_3', vgg_network['conv4_3'])\n",
    "    vgg_network['conv4_4'] = vggConv('conv4_4', vgg_network['relu4_3'])\n",
    "    vgg_network['relu4_4'] = vggRelu('relu4_4', vgg_network['conv4_4'])\n",
    "    vgg_network['pool4'] = vggPool(vgg_network['relu4_4'])\n",
    "\n",
    "    # Hidden layer 5\n",
    "    vgg_network['conv5_1'] = vggConv('conv5_1', vgg_network['pool4'])\n",
    "    vgg_network['relu5_1'] = vggRelu('relu5_1', vgg_network['conv5_1'])\n",
    "    vgg_network['conv5_2'] = vggConv('conv5_2', vgg_network['relu5_1'])\n",
    "    vgg_network['relu5_2'] = vggRelu('relu5_2', vgg_network['conv5_2'])\n",
    "    vgg_network['conv5_3'] = vggConv('conv5_3', vgg_network['relu5_2'])\n",
    "    vgg_network['relu5_3'] = vggRelu('relu5_3', vgg_network['conv5_3'])\n",
    "    vgg_network['conv5_4'] = vggConv('conv5_4', vgg_network['relu5_3'])\n",
    "    vgg_network['relu5_4'] = vggRelu('relu5_4', vgg_network['conv5_4'])\n",
    "\n",
    "    return vgg_network\n",
    "\n",
    "def createNetwork(L):\n",
    "    # Input layer\n",
    "    W = weight(width=3, height=3, input_channels=1, output_channels=64, variable_name=\"input_layer/weight\")\n",
    "    B = bias(output_channels=64, variable_name=\"input_layer/bias\")\n",
    "    input_layer = tf.nn.bias_add(tf.nn.conv2d(L, W, strides=[1, 1, 1, 1], padding=\"SAME\"), B)\n",
    "    input_layer = tf.nn.relu(input_layer, name=\"input_later/relu\")\n",
    "\n",
    "    # VGG layers\n",
    "    vgg_network = generateVGGLayers(input_layer)\n",
    "    vgg_pool5 = maxPool(vgg_network[\"relu5_3\"])\n",
    "\n",
    "    # Hidden layer 1 (scale up(pool5) + pool4)\n",
    "    vgg_pool4 = vgg_network[\"pool4\"]\n",
    "    W1 = weight(4, 4, vgg_pool4.shape[3].value, vgg_pool5.shape[3].value, \"hidden_layer/1/weight\")\n",
    "    B1 = bias(vgg_pool4.shape[3].value, \"hidden_layer/1/bias\")\n",
    "    conv_trans1 = conv2dTranspose(vgg_pool5, W1, B1, output_shape=tf.shape(vgg_pool4))\n",
    "    hypercolumns = tf.add(conv_trans1, vgg_pool4, name=\"hidden_layer/1/fuse\")\n",
    "\n",
    "    # Hidden layer 2 (scale up (scale up(pool5) + pool4) + pool3)\n",
    "    vgg_pool3 = vgg_network[\"pool3\"]\n",
    "    W2 = weight(4, 4, vgg_pool3.shape[3].value, vgg_pool4.shape[3].value,\"hidden_layer/2/weight\")\n",
    "    B2 = bias(vgg_pool3.shape[3].value, \"hidden_layer/2/bias\")\n",
    "    conv_trans2 = conv2dTranspose(hypercolumns, W2, B2, output_shape=tf.shape(vgg_pool3))\n",
    "    hypercolumns = tf.add(conv_trans2, vgg_pool3, name=\"hidden_layer/2/fuse\")\n",
    "    \n",
    "    # Output layer (scale up (scale up (scale up(pool5) + pool4) + pool3) to picture size)\n",
    "    input_shape = tf.shape(L)\n",
    "    output_shape = tf.stack([input_shape[0], input_shape[1], input_shape[2], 2])\n",
    "    W3 = weight(16, 16, 2, vgg_pool3.shape[3].value, \"output_layer/weight\")\n",
    "    B3 = bias(2, \"output_layer/bias\")\n",
    "    AB = conv2dTranspose(hypercolumns, W3, B3, output_shape=output_shape, stride=8)\n",
    "    \n",
    "    # Output LAB values\n",
    "    return tf.concat([L, AB], 3, name=\"colorized_image\") # [?, pic_width, pic_height, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToLab(image):\n",
    "    lab = color.rgb2lab(image)\n",
    "    X_batch = lab[:,:,0]\n",
    "    Y_batch = lab[:,:,1:]\n",
    "    return X_batch.reshape(X_batch.shape+(1,)), lab\n",
    "\n",
    "def parseImage(filename):\n",
    "    image = tf.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize_images(image, [400, 400], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test_paths = ['woman.jpg']\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(file_test_paths)\n",
    "dataset = dataset.map(parseImage)\n",
    "dataset = dataset.map(lambda image: \n",
    "    tuple(tf.py_func(\n",
    "        convertToLab, [image], [tf.double, tf.double]\n",
    "    ))\n",
    ")\n",
    "dataset = dataset.batch(1)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, None, None, 1], name='L_image')\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, None, None, 3], name=\"LAB_image\")\n",
    "\n",
    "Y = createNetwork(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 400\n",
    "# Define the loss function \n",
    "#loss = tf.reduce_mean(2 * tf.nn.l2_loss(Y - Y_)) / (IMAGE_SIZE * IMAGE_SIZE * 100 * 100)\n",
    "#tf.summary.scalar(\"loss\", loss)\n",
    "loss = tf.reduce_mean(tf.squared_difference(Y, Y_), 1)\n",
    "loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.0001, beta1=0.9).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from the train set:\n",
      "Step: 0\n",
      "Round: 0\n",
      "Loss: 138.879\n",
      "Round: 1\n",
      "Loss: 110.635\n",
      "Round: 2\n",
      "Loss: 99.709\n",
      "Round: 3\n",
      "Loss: 94.3805\n",
      "Round: 4\n",
      "Loss: 88.827\n",
      "Round: 5\n",
      "Loss: 80.8492\n",
      "Round: 6\n",
      "Loss: 71.7452\n",
      "Round: 7\n",
      "Loss: 72.8402\n",
      "Round: 8\n",
      "Loss: 61.305\n",
      "Round: 9\n",
      "Loss: 58.8664\n",
      "End of training dataset.\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "next_element = iterator.get_next()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  \n",
    "    # initialize the variables\n",
    "    sess.run(init)\n",
    "\n",
    "    # initialize the queue threads to start to shovel data\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    print \"from the train set:\"\n",
    "    # images, labels = iterator.get_next()\n",
    "    step = 0\n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "            elem = sess.run(next_element)\n",
    "            print \"Step:\", step\n",
    "            for i in range(10):\n",
    "                print \"Round:\", i\n",
    "                _, luss = sess.run([optimizer, loss_mean], feed_dict={\n",
    "                    X: elem[0], Y_: elem[1]\n",
    "                })\n",
    "                print \"Loss:\", luss\n",
    "            step += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            saver.save(sess, './model/' + 'model.ckpt', global_step=step+1)\n",
    "            print(\"End of training dataset.\")\n",
    "            break\n",
    "            \n",
    "    # stop our queue threads and properly close the session\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
