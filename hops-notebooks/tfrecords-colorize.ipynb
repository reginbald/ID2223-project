{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tSession 4769 unexpectedly reached final status 'dead'. See logs:\n",
      "stdout: \n",
      "18/01/03 01:08:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "18/01/03 01:08:45 INFO RMProxy: Connecting to ResourceManager at /10.0.104.190:8032\n",
      "18/01/03 01:08:45 INFO Client: Requesting a new application from cluster with 30 NodeManagers\n",
      "18/01/03 01:08:45 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (216000 MB per container)\n",
      "18/01/03 01:08:45 INFO Client: Will allocate AM container, with 17740 MB memory including 1612 MB overhead\n",
      "18/01/03 01:08:45 INFO Client: Setting up container launch context for our AM\n",
      "18/01/03 01:08:45 INFO Client: Setting up the launch environment for our AM container\n",
      "18/01/03 01:08:45 INFO Client: Preparing resources for our AM container\n",
      "18/01/03 01:08:47 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "18/01/03 01:08:49 INFO Client: Uploading resource file:/tmp/spark-b3a08e9e-686c-44f5-97af-dff40b46e2f6/__spark_libs__9162536712285590544.zip -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/__spark_libs__9162536712285590544.zip\n",
      "18/01/03 01:08:50 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/livy-rsc-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/livy-rsc-0.4.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/netty-all-4.0.29.Final.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/netty-all-4.0.29.Final.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/livy-api-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/livy-api-0.4.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/Projects/colorizeML2/imbd_face_dataset/tensorflow-hadoop-1.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/livy-repl_2.11-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/livy-repl_2.11-0.4.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/livy-core_2.11-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/livy-core_2.11-0.4.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/commons-codec-1.9.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/commons-codec-1.9.jar\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/colorizeML2__jriv0000/colorizeML2__jriv0000__kstore.jks#k_certificate\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/colorizeML2__jriv0000/colorizeML2__jriv0000__tstore.jks#t_certificate\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/spark/log4j.properties\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/colorizeML2__jriv0000/colorizeML2__jriv0000__cert.key#material_passwd\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/spark/python/lib/pyspark.zip -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/pyspark.zip\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/spark/python/lib/py4j-0.10.4-src.zip -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/py4j-0.10.4-src.zip\n",
      "18/01/03 01:08:51 WARN Client: Same path resource file:/srv/hops/spark/python/lib/pyspark.zip added multiple times to distributed cache.\n",
      "18/01/03 01:08:51 WARN Client: Same path resource file:/srv/hops/spark/python/lib/py4j-0.10.4-src.zip added multiple times to distributed cache.\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/tmp/spark-b3a08e9e-686c-44f5-97af-dff40b46e2f6/__spark_conf__1257602088906998330.zip -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/__spark_conf__.zip\n",
      "18/01/03 01:08:52 INFO SecurityManager: Changing view acls to: livy,colorizeML2__jriv0000\n",
      "18/01/03 01:08:52 INFO SecurityManager: Changing modify acls to: livy,colorizeML2__jriv0000\n",
      "18/01/03 01:08:52 INFO SecurityManager: Changing view acls groups to: \n",
      "18/01/03 01:08:52 INFO SecurityManager: Changing modify acls groups to: \n",
      "18/01/03 01:08:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(livy, colorizeML2__jriv0000); groups with view permissions: Set(); users  with modify permissions: Set(livy, colorizeML2__jriv0000); groups with modify permissions: Set()\n",
      "18/01/03 01:08:52 INFO Client: Submitting application application_1513605045578_2181 to ResourceManager\n",
      "18/01/03 01:08:52 INFO YarnClientImpl: Submitted application application_1513605045578_2181\n",
      "18/01/03 01:08:52 INFO Client: Application report for application_1513605045578_2181 (state: ACCEPTED)\n",
      "18/01/03 01:08:52 INFO Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: [Wed Jan 03 01:08:52 +0100 2018] Application is Activated, waiting for resources to be assigned for AM.  Details : AM Partition = <DEFAULT_PARTITION> ; Partition Resource = <memory:6480000, vCores:620, gpus:4> ; Queue's Absolute capacity = 100.0 % ; Queue's Absolute used capacity = 79.19355 % ; Queue's Absolute max capacity = 100.0 % ; \n",
      "\t ApplicationMaster host: N/A\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: default\n",
      "\t start time: 1514938132125\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://hadoop30:8088/proxy/application_1513605045578_2181/\n",
      "\t user: colorizeML2__jriv0000\n",
      "18/01/03 01:08:52 INFO ShutdownHookManager: Shutdown hook called\n",
      "18/01/03 01:08:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-b3a08e9e-686c-44f5-97af-dff40b46e2f6\n",
      "\n",
      "stderr: \n",
      "Warning: Skip remote jar hdfs:///Projects/colorizeML2/imbd_face_dataset/tensorflow-hadoop-1.0-SNAPSHOT.jar.\n",
      "\n",
      "YARN Diagnostics: \n",
      "YARN Diagnostics:\n",
      "[Wed Jan 03 01:08:52 +0100 2018] Application is Activated, waiting for resources to be assigned for AM.  Details : AM Partition = <DEFAULT_PARTITION> ; Partition Resource = <memory:6480000, vCores:620, gpus:4> ; Queue's Absolute capacity = 100.0 % ; Queue's Absolute used capacity = 79.19355 % ; Queue's Absolute max capacity = 100.0 % ; .\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "def mnist_fun(args, ctx):\n",
    "    \n",
    "    def print_log(worker_num, arg):\n",
    "        print(\"%d: \" %worker_num)\n",
    "        print(arg)\n",
    "\n",
    "    from tensorflowonspark import TFNode\n",
    "    from datetime import datetime\n",
    "    import getpass\n",
    "    import math\n",
    "    import numpy\n",
    "    import os\n",
    "    import signal\n",
    "    import tensorflow as tf\n",
    "    import time\n",
    "    from skimage.color import lab2rgb\n",
    "  \n",
    "    # Used to get TensorBoard logdir for TensorBoard that show up in HopsWorks\n",
    "    from hops import tensorboard\n",
    "\n",
    "    worker_num = ctx.worker_num\n",
    "    job_name = ctx.job_name\n",
    "    task_index = ctx.task_index\n",
    "    cluster_spec = ctx.cluster_spec\n",
    "    num_workers = len(cluster_spec['worker'])\n",
    "\n",
    "    # Delay PS nodes a bit, since workers seem to reserve GPUs more quickly/reliably (w/o conflict)\n",
    "    if job_name == \"ps\":\n",
    "        time.sleep((worker_num + 1) * 5)\n",
    "\n",
    "    # Parameters\n",
    "    batch_size   = 100\n",
    "\n",
    "    # Get TF cluster and server instances\n",
    "    cluster, server = TFNode.start_cluster_server(ctx, 1, args.rdma)\n",
    "\n",
    "    def read_tfr_examples(path, batch_size=100, num_epochs=None, task_index=None, num_workers=None):\n",
    "        print_log(worker_num, \"num_epochs: {0}\".format(num_epochs))\n",
    "\n",
    "        # Setup queue of TFRecord filenames\n",
    "        tf_record_pattern = os.path.join(path, 'part-*')\n",
    "        files = tf.gfile.Glob(tf_record_pattern)\n",
    "        queue_name = \"file_queue\"\n",
    "\n",
    "        # split input files across workers, if specified\n",
    "        if task_index is not None and num_workers is not None:\n",
    "            num_files = len(files)\n",
    "            files = files[task_index:num_files:num_workers]\n",
    "            queue_name = \"file_queue_{0}\".format(task_index)\n",
    "\n",
    "        print_log(worker_num, \"files: {0}\".format(files))\n",
    "        file_queue = tf.train.string_input_producer(files, shuffle=False, capacity=1000, num_epochs=num_epochs, name=queue_name)\n",
    "\n",
    "        # Setup reader for examples\n",
    "        reader = tf.TFRecordReader(name=\"reader\")\n",
    "        _, serialized = reader.read(file_queue)\n",
    "        feature_def = {\n",
    "            'L': tf.FixedLenFeature([65536], tf.float32), \n",
    "            'A': tf.FixedLenFeature([65536], tf.float32), \n",
    "            'B': tf.FixedLenFeature([65536], tf.float32) \n",
    "        }\n",
    "        \n",
    "        features = tf.parse_single_example(serialized, feature_def)\n",
    "        L = tf.reshape(tf.to_float(features['L']), [256, 256, 1])\n",
    "        \n",
    "        print_log(worker_num, \"L: {0}\".format(L))\n",
    "        A = tf.reshape(tf.to_float(features['A']), [256, 256, 1])\n",
    "        print_log(worker_num, \"A: {0}\".format(A))\n",
    "        B = tf.reshape(tf.to_float(features['B']), [256, 256, 1])\n",
    "        print_log(worker_num, \"B: {0}\".format(B))\n",
    "        AB = tf.concat([A, B], 2)\n",
    "\n",
    "        # Return a batch of examples\n",
    "        return tf.train.batch([L, AB], batch_size, num_threads=args.readers, name=\"batch\")\n",
    "    \n",
    "    def conv2DRelu(X, W, B, strides, padding):\n",
    "        # strides: [batch_step, height_step, width_step, channel_step] \n",
    "        return tf.nn.relu(tf.nn.conv2d(X, W, strides=strides, padding=padding) + B)\n",
    "\n",
    "    def conv2DTanh(X, W, B, strides, padding):\n",
    "        # strides: [batch_step, height_step, width_step, channel_step] \n",
    "        return tf.nn.tanh(tf.nn.conv2d(X, W, strides=strides, padding=padding) + B)\n",
    "\n",
    "    def weight(width, height, input_channels, output_channels, variable_name):\n",
    "        # [width, height, input channel, output channel]\n",
    "        W = tf.Variable(tf.truncated_normal([width, height, input_channels, output_channels], stddev=0.1), name=variable_name)\n",
    "        tf.summary.histogram(variable_name, W)\n",
    "        return W\n",
    "\n",
    "    def bias(outputChannels, variable_name):\n",
    "        B = tf.Variable(tf.zeros([outputChannels]), name=variable_name)\n",
    "        tf.summary.histogram(variable_name, B)\n",
    "        return B # bias for each output channel.\n",
    "\n",
    "    def upSampling2D(X, height, width):\n",
    "        return tf.image.resize_images(X, [height, width], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    def upSampleToOriginalSize(X, size):\n",
    "        return tf.image.resize_images(X, size, tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    def Conv2D(X, input_channels, output_channels, scan=3, activation='relu', padding='SAME', strides=1, layer_name=\"layer\"):\n",
    "        W = weight(scan, scan, input_channels, output_channels, layer_name + \"/weight\")\n",
    "        B = bias(output_channels, layer_name + \"/bias\")\n",
    "        if activation == 'relu':\n",
    "            Y = conv2DRelu(X, W, B, [1,strides,strides,1], padding)\n",
    "            return tf.nn.dropout(Y, tf.constant(0.75)) #pkeep\n",
    "            #return conv2DRelu(X, W, B, [1,strides,strides,1], padding)\n",
    "        else:\n",
    "            return conv2DTanh(X, W, B, [1,strides,strides,1], padding)\n",
    "        \n",
    "    def extractImage(L, Y):\n",
    "        Y_temp = tf.scalar_mul(128, Y)\n",
    "        A, B = tf.split(Y_temp, [1,1], axis=3)\n",
    "        A = tf.multiply(A, 128)\n",
    "        B = tf.multiply(B, 128)\n",
    "        LAB = tf.concat([L,A,B], 3)\n",
    "        #return tf.py_func(lab2rgb, [LAB], LAB.dtype)#tf.float32)\n",
    "        return LAB\n",
    "    \n",
    "    if job_name == \"ps\":\n",
    "        server.join()\n",
    "    elif job_name == \"worker\":\n",
    "        # Assigns ops to the local worker by default.\n",
    "        with tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:%d\" % task_index, cluster=cluster)):\n",
    "        \n",
    "            # Placeholders or QueueRunner/Readers for input data\n",
    "            num_epochs = 1 if args.mode == \"inference\" else None if args.epochs == 0 else args.epochs\n",
    "            #num_epochs = 100\n",
    "            index = task_index if args.mode == \"inference\" else None\n",
    "            workers = num_workers if args.mode == \"inference\" else None\n",
    "\n",
    "            images = TFNode.hdfs_path(ctx, args.images)\n",
    "            X, Y_ = read_tfr_examples(images, batch_size, num_epochs, index, workers)\n",
    "            \n",
    "            Y1 = Conv2D(X, 1, 8, 3, 'relu', 'SAME', 2, \"input_layer\")\n",
    "            Y2 = Conv2D(Y1, 8, 8, 3, 'relu', 'SAME', 1, \"hidden_layer_1\")\n",
    "            Y3 = Conv2D(Y2, 8, 16, 3, 'relu', 'SAME', 1, \"hidden_layer_2\")\n",
    "            Y4 = Conv2D(Y3, 16, 16, 3, 'relu', 'SAME', 2, \"hidden_layer_3\")\n",
    "            Y5 = Conv2D(Y4, 16, 32, 3, 'relu', 'SAME', 1, \"hidden_layer_4\")\n",
    "            Y6 = Conv2D(Y5, 32, 32, 3, 'relu', 'SAME', 2, \"hidden_layer_5\")\n",
    "            Y7 = upSampling2D(Y6, 64, 64)\n",
    "            Y8 = Conv2D(Y7, 32, 32, 3, 'relu', 'SAME', 1, \"hidden_layer_6\")\n",
    "            Y9 = upSampling2D(Y8, 128, 128)\n",
    "            Y10 = Conv2D(Y9, 32, 16, 3, 'relu', 'SAME', 1, \"hidden_layer_7\")\n",
    "            Y11 = upSampling2D(Y10, 256, 256)\n",
    "            Y = Conv2D(Y11, 16, 2, 3, 'tanh', 'SAME', 1, \"output_layer\")\n",
    "\n",
    "            '''Display pics'''\n",
    "            tf.summary.image(\"bw_img\", X)\n",
    "            #tf.summary.image(\"color_img\", extractImage(X, Y_))\n",
    "            #tf.summary.image(\"colorized_img\", extractImage(X, Y))\n",
    "\n",
    "            # Define the loss function \n",
    "            loss = tf.reduce_mean(tf.squared_difference(Y, Y_), 1)\n",
    "            tf.summary.scalar(\"mean_loss\", tf.reduce_mean(loss))\n",
    "\n",
    "            global_step = tf.Variable(0, name=\"global_step\")\n",
    "            # Define an optimizer\n",
    "            train_op = tf.train.AdamOptimizer(0.00001).minimize(loss, global_step=global_step)\n",
    "\n",
    "            '''TODO GERA THETTA'''\n",
    "            ## Test trained model\n",
    "            #label = tf.argmax(y_, 1, name=\"label\")\n",
    "            #prediction = tf.argmax(y, 1,name=\"prediction\")\n",
    "            #correct_prediction = tf.equal(prediction, label)\n",
    "            #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "            #tf.summary.scalar(\"acc\", accuracy)\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "            summary_op = tf.summary.merge_all()\n",
    "            init_op = tf.global_variables_initializer()\n",
    "\n",
    "            # Create a \"supervisor\", which oversees the training process and stores model state into HDFS\n",
    "            logdir = tensorboard.logdir()\n",
    "            print(\"tensorflow model path: {0}\".format(logdir))\n",
    "\n",
    "            if job_name == \"worker\" and task_index == 0:\n",
    "                summary_writer = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())\n",
    "\n",
    "            if args.mode == \"train\":\n",
    "                sv = tf.train.Supervisor(is_chief=(task_index == 0),\n",
    "                                       logdir=logdir,\n",
    "                                       init_op=init_op,\n",
    "                                       summary_op=None,\n",
    "                                       summary_writer=None,\n",
    "                                       saver=saver,\n",
    "                                       global_step=global_step,\n",
    "                                       stop_grace_secs=300,\n",
    "                                       save_model_secs=10)\n",
    "            else:\n",
    "                sv = tf.train.Supervisor(is_chief=(task_index == 0),\n",
    "                                       logdir=logdir,\n",
    "                                       summary_op=None,\n",
    "                                       saver=saver,\n",
    "                                       global_step=global_step,\n",
    "                                       stop_grace_secs=300,\n",
    "                                       save_model_secs=0)\n",
    "            output_dir = TFNode.hdfs_path(ctx, args.output)\n",
    "            output_file = tf.gfile.Open(\"{0}/part-{1:05d}\".format(output_dir, worker_num), mode='w')\n",
    "\n",
    "            # The supervisor takes care of session initialization, restoring from\n",
    "            # a checkpoint, and closing when done or an error occurs.\n",
    "    with sv.managed_session(server.target) as sess:\n",
    "        print(\"{0} session ready\".format(datetime.now().isoformat()))\n",
    "\n",
    "        # Loop until the supervisor shuts down or 1000000 steps have completed.\n",
    "        step = 0\n",
    "        count = 0\n",
    "        while not sv.should_stop() and step < args.steps:\n",
    "        # Run a training step asynchronously.\n",
    "        # See `tf.train.SyncReplicasOptimizer` for additional details on how to\n",
    "        # perform *synchronous* training.\n",
    "\n",
    "            # using QueueRunners/Readers\n",
    "            if args.mode == \"train\":\n",
    "                #if (step % 100 == 0):\n",
    "                    #print(\"{0} step: {1} accuracy: {2}\".format(datetime.now().isoformat(), step, sess.run(accuracy)))\n",
    "                _, summary, step = sess.run([train_op, summary_op, global_step])\n",
    "                if sv.is_chief:\n",
    "                    summary_writer.add_summary(summary, step)\n",
    "            #else: # args.mode == \"inference\"\n",
    "            #    #labels, pred, acc = sess.run([label, prediction, accuracy])\n",
    "            #    labels, pred = sess.run([label, prediction])\n",
    "            #    #print(\"label: {0}, pred: {1}\".format(labels, pred))\n",
    "            #    print(\"acc: {0}\".format(acc))\n",
    "            #    for i in range(len(labels)):\n",
    "            #        count += 1\n",
    "            #        output_file.write(\"{0} {1}\\n\".format(labels[i], pred[i]))\n",
    "            #    print(\"count: {0}\".format(count))\n",
    "\n",
    "        if args.mode == \"inference\":\n",
    "            output_file.close()\n",
    "            # Delay chief worker from shutting down supervisor during inference, since it can load model, start session,\n",
    "            # run inference and request stop before the other workers even start/sync their sessions.\n",
    "        if task_index == 0:\n",
    "            time.sleep(60)\n",
    "\n",
    "        # Ask for all the services to stop.\n",
    "        print(\"{0} stopping supervisor\".format(datetime.now().isoformat()))\n",
    "        sv.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tSession 4769 unexpectedly reached final status 'dead'. See logs:\n",
      "stdout: \n",
      "18/01/03 01:08:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "18/01/03 01:08:45 INFO RMProxy: Connecting to ResourceManager at /10.0.104.190:8032\n",
      "18/01/03 01:08:45 INFO Client: Requesting a new application from cluster with 30 NodeManagers\n",
      "18/01/03 01:08:45 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (216000 MB per container)\n",
      "18/01/03 01:08:45 INFO Client: Will allocate AM container, with 17740 MB memory including 1612 MB overhead\n",
      "18/01/03 01:08:45 INFO Client: Setting up container launch context for our AM\n",
      "18/01/03 01:08:45 INFO Client: Setting up the launch environment for our AM container\n",
      "18/01/03 01:08:45 INFO Client: Preparing resources for our AM container\n",
      "18/01/03 01:08:47 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "18/01/03 01:08:49 INFO Client: Uploading resource file:/tmp/spark-b3a08e9e-686c-44f5-97af-dff40b46e2f6/__spark_libs__9162536712285590544.zip -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/__spark_libs__9162536712285590544.zip\n",
      "18/01/03 01:08:50 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/livy-rsc-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/livy-rsc-0.4.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/netty-all-4.0.29.Final.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/netty-all-4.0.29.Final.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/rsc-jars/livy-api-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/livy-api-0.4.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/Projects/colorizeML2/imbd_face_dataset/tensorflow-hadoop-1.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/livy-repl_2.11-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/livy-repl_2.11-0.4.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/livy-core_2.11-0.4.0-SNAPSHOT.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/livy-core_2.11-0.4.0-SNAPSHOT.jar\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/livy-server/repl_2.11-jars/commons-codec-1.9.jar -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/commons-codec-1.9.jar\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/colorizeML2__jriv0000/colorizeML2__jriv0000__kstore.jks#k_certificate\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/colorizeML2__jriv0000/colorizeML2__jriv0000__tstore.jks#t_certificate\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/spark/log4j.properties\n",
      "18/01/03 01:08:51 INFO Client: Source and destination file systems are the same. Not copying hdfs:/user/glassfish/kafkacerts/colorizeML2__jriv0000/colorizeML2__jriv0000__cert.key#material_passwd\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/spark/python/lib/pyspark.zip -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/pyspark.zip\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/srv/hops/spark/python/lib/py4j-0.10.4-src.zip -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/py4j-0.10.4-src.zip\n",
      "18/01/03 01:08:51 WARN Client: Same path resource file:/srv/hops/spark/python/lib/pyspark.zip added multiple times to distributed cache.\n",
      "18/01/03 01:08:51 WARN Client: Same path resource file:/srv/hops/spark/python/lib/py4j-0.10.4-src.zip added multiple times to distributed cache.\n",
      "18/01/03 01:08:51 INFO Client: Uploading resource file:/tmp/spark-b3a08e9e-686c-44f5-97af-dff40b46e2f6/__spark_conf__1257602088906998330.zip -> hdfs:/Projects/colorizeML2/Resources/.sparkStaging/application_1513605045578_2181/__spark_conf__.zip\n",
      "18/01/03 01:08:52 INFO SecurityManager: Changing view acls to: livy,colorizeML2__jriv0000\n",
      "18/01/03 01:08:52 INFO SecurityManager: Changing modify acls to: livy,colorizeML2__jriv0000\n",
      "18/01/03 01:08:52 INFO SecurityManager: Changing view acls groups to: \n",
      "18/01/03 01:08:52 INFO SecurityManager: Changing modify acls groups to: \n",
      "18/01/03 01:08:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(livy, colorizeML2__jriv0000); groups with view permissions: Set(); users  with modify permissions: Set(livy, colorizeML2__jriv0000); groups with modify permissions: Set()\n",
      "18/01/03 01:08:52 INFO Client: Submitting application application_1513605045578_2181 to ResourceManager\n",
      "18/01/03 01:08:52 INFO YarnClientImpl: Submitted application application_1513605045578_2181\n",
      "18/01/03 01:08:52 INFO Client: Application report for application_1513605045578_2181 (state: ACCEPTED)\n",
      "18/01/03 01:08:52 INFO Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: [Wed Jan 03 01:08:52 +0100 2018] Application is Activated, waiting for resources to be assigned for AM.  Details : AM Partition = <DEFAULT_PARTITION> ; Partition Resource = <memory:6480000, vCores:620, gpus:4> ; Queue's Absolute capacity = 100.0 % ; Queue's Absolute used capacity = 79.19355 % ; Queue's Absolute max capacity = 100.0 % ; \n",
      "\t ApplicationMaster host: N/A\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: default\n",
      "\t start time: 1514938132125\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://hadoop30:8088/proxy/application_1513605045578_2181/\n",
      "\t user: colorizeML2__jriv0000\n",
      "18/01/03 01:08:52 INFO ShutdownHookManager: Shutdown hook called\n",
      "18/01/03 01:08:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-b3a08e9e-686c-44f5-97af-dff40b46e2f6\n",
      "\n",
      "stderr: \n",
      "Warning: Skip remote jar hdfs:///Projects/colorizeML2/imbd_face_dataset/tensorflow-hadoop-1.0-SNAPSHOT.jar.\n",
      "\n",
      "YARN Diagnostics: \n",
      "YARN Diagnostics:\n",
      "[Wed Jan 03 01:08:52 +0100 2018] Application is Activated, waiting for resources to be assigned for AM.  Details : AM Partition = <DEFAULT_PARTITION> ; Partition Resource = <memory:6480000, vCores:620, gpus:4> ; Queue's Absolute capacity = 100.0 % ; Queue's Absolute used capacity = 79.19355 % ; Queue's Absolute max capacity = 100.0 % ; .\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from hops import util\n",
    "from hops import hdfs\n",
    "\n",
    "from tensorflowonspark import TFCluster\n",
    "\n",
    "sc = spark.sparkContext\n",
    "num_executors = util.num_executors(spark)\n",
    "num_ps = util.num_param_servers(spark)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--epochs\", help=\"number of epochs\", type=int, default=0)\n",
    "parser.add_argument(\"-f\", \"--format\", help=\"example format: (csv|pickle|tfr)\", choices=[\"csv\",\"pickle\",\"tfr\"], default=\"csv\")\n",
    "parser.add_argument(\"-i\", \"--images\", help=\"HDFS path to MNIST images in parallelized format\", default='/Projects/' + hdfs.project_name() + '/imbd_face_dataset/small_processed')\n",
    "#parser.add_argument(\"-i\", \"--images\", help=\"HDFS path to MNIST images in parallelized format\", default='/Projects/' + hdfs.project_name() + '/mnist/train/images')\n",
    "parser.add_argument(\"-l\", \"--labels\", help=\"HDFS path to MNIST labels in parallelized format\", default = '/Projects/' + hdfs.project_name() + '/mnist/train/labels')\n",
    "parser.add_argument(\"-m\", \"--model\", help=\"HDFS path to save/load model during train/test\", default=\"mnist_model\")\n",
    "#parser.add_argument(\"-m\", \"--model\", help=\"HDFS path to save/load model during train/test\", default='/Projects/' + hdfs.project_name() + '/imbd_face_dataset/model')\n",
    "parser.add_argument(\"-n\", \"--cluster_size\", help=\"number of nodes in the cluster (for Spark Standalone)\", type=int, default=num_executors)\n",
    "parser.add_argument(\"-o\", \"--output\", help=\"HDFS path to save test/inference output\", default=\"predictions\")\n",
    "parser.add_argument(\"-r\", \"--readers\", help=\"number of reader/enqueue threads\", type=int, default=1)\n",
    "parser.add_argument(\"-s\", \"--steps\", help=\"maximum number of steps\", type=int, default=1000)\n",
    "parser.add_argument(\"-tb\", \"--tensorboard\", help=\"launch tensorboard process\", action=\"store_true\")\n",
    "parser.add_argument(\"-X\", \"--mode\", help=\"train|inference\", default=\"train\")\n",
    "parser.add_argument(\"-c\", \"--rdma\", help=\"use rdma connection\", default=False)\n",
    "args = parser.parse_args()\n",
    "print(\"args:\",args)\n",
    "\n",
    "\n",
    "print(\"{0} ===== Start\".format(datetime.now().isoformat()))\n",
    "\n",
    "cluster = TFCluster.run(sc, mnist_fun, args, args.cluster_size, num_ps, args.tensorboard, TFCluster.InputMode.TENSORFLOW)\n",
    "cluster.shutdown()\n",
    "\n",
    "print(\"{0} ===== Stop\".format(datetime.now().isoformat()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
