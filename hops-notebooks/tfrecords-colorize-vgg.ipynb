{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6501</td><td>application_1513605045578_4017</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hadoop30:8088/proxy/application_1513605045578_4017/\">Link</a></td><td><a target=\"_blank\" href=\"http://hadoop23:8042/node/containerlogs/container_e28_1513605045578_4017_01_000001/colorizeML2__jriv0000\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "def colorize_fun(args, ctx):\n",
    "    \n",
    "    def print_log(worker_num, arg):\n",
    "        print(\"%d: \" %worker_num)\n",
    "        print(arg)\n",
    "\n",
    "    from tensorflowonspark import TFNode\n",
    "    from datetime import datetime\n",
    "    import getpass\n",
    "    import math\n",
    "    import numpy\n",
    "    import os\n",
    "    import signal\n",
    "    import tensorflow as tf\n",
    "    import time\n",
    "    #from skimage.color import lab2rgb\n",
    "    from hops import hdfs\n",
    "  \n",
    "    # Used to get TensorBoard logdir for TensorBoard that show up in HopsWorks\n",
    "    from hops import tensorboard\n",
    "\n",
    "    worker_num = ctx.worker_num\n",
    "    job_name = ctx.job_name\n",
    "    task_index = ctx.task_index\n",
    "    cluster_spec = ctx.cluster_spec\n",
    "    num_workers = len(cluster_spec['worker'])\n",
    "\n",
    "    # Delay PS nodes a bit, since workers seem to reserve GPUs more quickly/reliably (w/o conflict)\n",
    "    if job_name == \"ps\":\n",
    "        time.sleep((worker_num + 1) * 5)\n",
    "\n",
    "    # Parameters\n",
    "    batch_size = 10\n",
    "    num_epochs = 10000\n",
    "    \n",
    "\n",
    "    # Get TF cluster and server instances\n",
    "    cluster, server = TFNode.start_cluster_server(ctx, 1, args.rdma)\n",
    "    \n",
    "    def weight(width, height, input_channels, output_channels, variable_name):\n",
    "        # [width, height, input channel, output channel]\n",
    "        return tf.get_variable(variable_name, initializer=tf.truncated_normal([width, height, input_channels, output_channels], stddev=0.02))\n",
    "\n",
    "    def bias(output_channels, variable_name):\n",
    "        return tf.get_variable(variable_name, initializer=tf.constant(0.0, shape=[output_channels]))\n",
    "\n",
    "    def maxPool(X):\n",
    "        return tf.nn.max_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "    def conv2dTranspose(X, W, B, output_shape, stride=2):\n",
    "        # Lesa þetta: http://www.matthewzeiler.com/wp-content/uploads/2017/07/cvpr2010.pdf\n",
    "        conv2d = tf.nn.conv2d_transpose(X, W, output_shape, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "        return tf.nn.bias_add(conv2d, B)\n",
    "    \n",
    "    def generateVGGLayers(input_layer):\n",
    "        vgg_model = args.vgg[0][()]\n",
    "        vgg_network = {}\n",
    "\n",
    "        def vggVariable(values, name):\n",
    "            # Populate tensor with values\n",
    "            return tf.get_variable(\n",
    "                name=name, \n",
    "                initializer=tf.constant_initializer(values, dtype=tf.float32), \n",
    "                shape=values.shape\n",
    "            )\n",
    "\n",
    "        def mat2tf(kernels):\n",
    "            # matconvnet: [width, height, in_channels, out_channels]\n",
    "            # tensorflow: [height, width, in_channels, out_channels]\n",
    "            return numpy.transpose(kernels, (1, 0, 2, 3))\n",
    "\n",
    "        def vggConv(name, X):\n",
    "            weight = mat2tf(vgg_model[name]['kernels'])\n",
    "            bias = vgg_model[name]['bias'].reshape(-1) # flatten\n",
    "\n",
    "            weight = vggVariable(weight, \"vgg/\" + name + \"/weight\")\n",
    "            bias = vggVariable(bias, \"vgg/\" + name + \"/bias\")\n",
    "\n",
    "            X = tf.nn.conv2d(X, weight, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "            return tf.nn.bias_add(X, bias)\n",
    "\n",
    "        def vggRelu(name, X):\n",
    "            return tf.nn.relu(X, name=\"vgg/\" + name + \"/relu\")\n",
    "\n",
    "        def vggPool(X):\n",
    "            return tf.nn.avg_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "        # Hidden layer 1 \n",
    "        # conv1_2 -> relu1_2 -> pool1\n",
    "        vgg_network['conv1_2'] = vggConv('conv1_2', input_layer)\n",
    "        vgg_network['relu1_2'] = vggRelu('relu1_2', vgg_network['conv1_2'])\n",
    "        vgg_network['pool1'] = vggPool(vgg_network['relu1_2'])\n",
    "\n",
    "        # Hidden layer 2\n",
    "        # pool1 -> conv2_1 -> relu2_1 -> conv2_2 -> relu2_2 -> pool2\n",
    "        vgg_network['conv2_1'] = vggConv('conv2_1', vgg_network['pool1'])\n",
    "        vgg_network['relu2_1'] = vggRelu('relu2_1', vgg_network['conv2_1'])\n",
    "        vgg_network['conv2_2'] = vggConv('conv2_2', vgg_network['relu2_1'])\n",
    "        vgg_network['relu2_2'] = vggRelu('relu2_2', vgg_network['conv2_2'])\n",
    "        vgg_network['pool2'] = vggPool(vgg_network['relu2_2'])\n",
    "\n",
    "        # Hidden layer 3\n",
    "        # pool2 -> conv3_1 -> relu3_1 -> conv3_2 -> relu3_2 -> conv3_3 -> \n",
    "        # relu3_3 -> conv3_4 -> relu3_4 -> pool3\n",
    "        vgg_network['conv3_1'] = vggConv('conv3_1', vgg_network['pool2'])\n",
    "        vgg_network['relu3_1'] = vggRelu('relu3_1', vgg_network['conv3_1'])\n",
    "        vgg_network['conv3_2'] = vggConv('conv3_2', vgg_network['relu3_1'])\n",
    "        vgg_network['relu3_2'] = vggRelu('relu3_2', vgg_network['conv3_2'])\n",
    "        vgg_network['conv3_3'] = vggConv('conv3_3', vgg_network['relu3_2'])\n",
    "        vgg_network['relu3_3'] = vggRelu('relu3_3', vgg_network['conv3_3'])\n",
    "        vgg_network['conv3_4'] = vggConv('conv3_4', vgg_network['relu3_3'])\n",
    "        vgg_network['relu3_4'] = vggRelu('relu3_4', vgg_network['conv3_4'])\n",
    "        vgg_network['pool3'] = vggPool(vgg_network['relu3_4'])\n",
    "\n",
    "        # Hidden layer 4\n",
    "        # pool3 -> conv4_1 -> relu4_1 -> conv4_2 -> relu4_2 -> conv4_3 -> \n",
    "        # relu4_3 -> conv4_4 -> relu4_4 -> pool4\n",
    "        vgg_network['conv4_1'] = vggConv('conv4_1', vgg_network['pool3'])\n",
    "        vgg_network['relu4_1'] = vggRelu('relu4_1', vgg_network['conv4_1'])\n",
    "        vgg_network['conv4_2'] = vggConv('conv4_2', vgg_network['relu4_1'])\n",
    "        vgg_network['relu4_2'] = vggRelu('relu4_2', vgg_network['conv4_2'])\n",
    "        vgg_network['conv4_3'] = vggConv('conv4_3', vgg_network['relu4_2'])\n",
    "        vgg_network['relu4_3'] = vggRelu('relu4_3', vgg_network['conv4_3'])\n",
    "        vgg_network['conv4_4'] = vggConv('conv4_4', vgg_network['relu4_3'])\n",
    "        vgg_network['relu4_4'] = vggRelu('relu4_4', vgg_network['conv4_4'])\n",
    "        vgg_network['pool4'] = vggPool(vgg_network['relu4_4'])\n",
    "\n",
    "        # Hidden layer 5\n",
    "        # pool4 -> conv5_1 -> relu5_1 -> conv5_2 -> relu5_2 -> conv5_3 -> \n",
    "        # relu5_3 -> conv5_4 -> relu5_4\n",
    "        vgg_network['conv5_1'] = vggConv('conv5_1', vgg_network['pool4'])\n",
    "        vgg_network['relu5_1'] = vggRelu('relu5_1', vgg_network['conv5_1'])\n",
    "        vgg_network['conv5_2'] = vggConv('conv5_2', vgg_network['relu5_1'])\n",
    "        vgg_network['relu5_2'] = vggRelu('relu5_2', vgg_network['conv5_2'])\n",
    "        vgg_network['conv5_3'] = vggConv('conv5_3', vgg_network['relu5_2'])\n",
    "        vgg_network['relu5_3'] = vggRelu('relu5_3', vgg_network['conv5_3'])\n",
    "        vgg_network['conv5_4'] = vggConv('conv5_4', vgg_network['relu5_3'])\n",
    "        vgg_network['relu5_4'] = vggRelu('relu5_4', vgg_network['conv5_4'])\n",
    "\n",
    "        return vgg_network\n",
    "        \n",
    "    def createNetwork(L):\n",
    "        # Input layer\n",
    "        W = weight(width=3, height=3, input_channels=1, output_channels=64, variable_name=\"input_layer/weight\")\n",
    "        B = bias(output_channels=64, variable_name=\"input_layer/bias\")\n",
    "        input_layer = tf.nn.bias_add(tf.nn.conv2d(L, W, strides=[1, 1, 1, 1], padding=\"SAME\"), B)\n",
    "        input_layer = tf.nn.relu(input_layer, name=\"input_later/relu\")\n",
    "\n",
    "        # VGG layers\n",
    "        vgg_network = generateVGGLayers(input_layer)\n",
    "        vgg_pool5 = maxPool(vgg_network[\"relu5_3\"])\n",
    "\n",
    "        # Hidden layer 1 (scale up(vgg_pool5) + vgg_pool4)\n",
    "        vgg_pool4 = vgg_network[\"pool4\"]\n",
    "        W1 = weight(4, 4, vgg_pool4.shape[3].value, vgg_pool5.shape[3].value, \"hidden_layer/1/weight\")\n",
    "        B1 = bias(vgg_pool4.shape[3].value, \"hidden_layer/1/bias\")\n",
    "        conv_trans1 = conv2dTranspose(vgg_pool5, W1, B1, output_shape=tf.shape(vgg_pool4))\n",
    "        hypercolumns = tf.add(conv_trans1, vgg_pool4, name=\"hidden_layer/1/fuse\")\n",
    "\n",
    "        # Hidden layer 2 (scale up (scale up(vgg_pool5) + vgg_pool4) + vgg_pool3)\n",
    "        vgg_pool3 = vgg_network[\"pool3\"]\n",
    "        W2 = weight(4, 4, vgg_pool3.shape[3].value, vgg_pool4.shape[3].value,\"hidden_layer/2/weight\")\n",
    "        B2 = bias(vgg_pool3.shape[3].value, \"hidden_layer/2/bias\")\n",
    "        conv_trans2 = conv2dTranspose(hypercolumns, W2, B2, output_shape=tf.shape(vgg_pool3))\n",
    "        hypercolumns = tf.add(conv_trans2, vgg_pool3, name=\"hidden_layer/2/fuse\")\n",
    "\n",
    "        # Output layer (scale up (scale up (scale up(vgg_pool5) + vgg_pool4) + vgg_pool3) to picture size)\n",
    "        input_shape = tf.shape(L)\n",
    "        output_shape = tf.stack([input_shape[0], input_shape[1], input_shape[2], 2])\n",
    "        W3 = weight(16, 16, 2, vgg_pool3.shape[3].value, \"output_layer/weight\")\n",
    "        B3 = bias(2, \"output_layer/bias\")\n",
    "        AB = conv2dTranspose(hypercolumns, W3, B3, output_shape=output_shape, stride=8)\n",
    "\n",
    "        # Output LAB values\n",
    "        return tf.concat([L, AB], 3, name=\"colorized_image\") # [?, pic_width, pic_height, 3]\n",
    "\n",
    "    def readTFRecords(path, batch_size=100, num_epochs=None, task_index=None, num_workers=None):\n",
    "        print_log(worker_num, \"num_epochs: {0}\".format(num_epochs))\n",
    "\n",
    "        # Setup queue of TFRecord filenames\n",
    "        tf_record_pattern = os.path.join(path, 'part-*')\n",
    "        files = tf.gfile.Glob(tf_record_pattern)\n",
    "        queue_name = \"file_queue\"\n",
    "\n",
    "        # split input files across workers, if specified\n",
    "        if task_index is not None and num_workers is not None:\n",
    "            num_files = len(files)\n",
    "            files = files[task_index:num_files:num_workers]\n",
    "            queue_name = \"file_queue_{0}\".format(task_index)\n",
    "\n",
    "        print_log(worker_num, \"files: {0}\".format(files))\n",
    "        file_queue = tf.train.string_input_producer(files, shuffle=False, capacity=1000, num_epochs=num_epochs, name=queue_name)\n",
    "\n",
    "        # Setup reader for examples\n",
    "        reader = tf.TFRecordReader(name=\"reader\")\n",
    "        _, serialized = reader.read(file_queue)\n",
    "        feature_def = {\n",
    "            'L': tf.FixedLenFeature([65536], tf.float32), \n",
    "            'A': tf.FixedLenFeature([65536], tf.float32), \n",
    "            'B': tf.FixedLenFeature([65536], tf.float32) \n",
    "        }\n",
    "        \n",
    "        features = tf.parse_single_example(serialized, feature_def)\n",
    "        L = tf.reshape(tf.to_float(features['L']), [256, 256, 1])\n",
    "        \n",
    "        print_log(worker_num, \"L: {0}\".format(L))\n",
    "        A = tf.multiply(tf.reshape(tf.to_float(features['A']), [256, 256, 1]), 128)\n",
    "        print_log(worker_num, \"A: {0}\".format(A))\n",
    "        B = tf.multiply(tf.reshape(tf.to_float(features['B']), [256, 256, 1]), 128)\n",
    "        print_log(worker_num, \"B: {0}\".format(B))\n",
    "        LAB = tf.concat([L, A, B], 2)\n",
    "\n",
    "        # Return a batch of examples\n",
    "        return tf.train.batch([L, LAB], batch_size, num_threads=args.readers, name=\"batch\")\n",
    "        \n",
    "    def convert2RGB(lab):\n",
    "        return map(lambda x: lab2rgb(x.astype(numpy.float32)), lab)\n",
    "    \n",
    "    def extractImage(LAB):\n",
    "        return LAB#tf.py_func(convert2RGB, [LAB], tf.float32)\n",
    "\n",
    "    \n",
    "    if job_name == \"ps\":\n",
    "        server.join()\n",
    "    elif job_name == \"worker\":\n",
    "        # Assigns ops to the local worker by default.\n",
    "        with tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:%d\" % task_index, cluster=cluster)):\n",
    "            index = task_index if args.mode == \"inference\" else None\n",
    "            workers = num_workers if args.mode == \"inference\" else None\n",
    "\n",
    "            images = TFNode.hdfs_path(ctx, args.images)\n",
    "            X, Y_ = readTFRecords(images, batch_size, num_epochs, index, workers)\n",
    "            \n",
    "            Y = createNetwork(X)\n",
    "\n",
    "            '''Display pics'''\n",
    "            tf.summary.image(\"bw_img\", X)\n",
    "            tf.summary.image(\"color_img\", extractImage(Y_))\n",
    "            tf.summary.image(\"colorized_img\", extractImage(Y))\n",
    "\n",
    "            # Define the loss function \n",
    "            loss = tf.reduce_mean(tf.squared_difference(Y, Y_), 1)\n",
    "            tf.summary.scalar(\"loss\", tf.reduce_mean(loss))\n",
    "\n",
    "            global_step = tf.Variable(0, name=\"global_step\")\n",
    "            # Define an optimizer\n",
    "            train_op = tf.train.AdamOptimizer(0.0001, beta1=0.9).minimize(loss, global_step=global_step)\n",
    "\n",
    "            # Test trained model\n",
    "            label = tf.argmax(Y_, 1, name=\"label\")\n",
    "            prediction = tf.argmax(Y, 1,name=\"prediction\")\n",
    "            correct_prediction = tf.equal(prediction, label)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "            tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "            summary_op = tf.summary.merge_all()\n",
    "            init_op = tf.global_variables_initializer()\n",
    "\n",
    "            # Create a \"supervisor\", which oversees the training process and stores model state into HDFS\n",
    "            logdir = tensorboard.logdir()\n",
    "            print(\"tensorflow model path: {0}\".format(logdir))\n",
    "\n",
    "            if job_name == \"worker\" and task_index == 0:\n",
    "                summary_writer = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())\n",
    "\n",
    "            if args.mode == \"train\":\n",
    "                sv = tf.train.Supervisor(is_chief=(task_index == 0),\n",
    "                                       logdir=logdir,\n",
    "                                       init_op=init_op,\n",
    "                                       summary_op=None,\n",
    "                                       summary_writer=None,\n",
    "                                       saver=saver,\n",
    "                                       global_step=global_step,\n",
    "                                       stop_grace_secs=300,\n",
    "                                       save_model_secs=10)\n",
    "            else:\n",
    "                sv = tf.train.Supervisor(is_chief=(task_index == 0),\n",
    "                                       logdir=logdir,\n",
    "                                       summary_op=None,\n",
    "                                       saver=saver,\n",
    "                                       global_step=global_step,\n",
    "                                       stop_grace_secs=300,\n",
    "                                       save_model_secs=0)\n",
    "            output_dir = TFNode.hdfs_path(ctx, args.output)\n",
    "            output_file = tf.gfile.Open(\"{0}/part-{1:05d}\".format(output_dir, worker_num), mode='w')\n",
    "\n",
    "            # The supervisor takes care of session initialization, restoring from\n",
    "            # a checkpoint, and closing when done or an error occurs.\n",
    "    with sv.managed_session(server.target) as sess:\n",
    "        print(\"{0} session ready\".format(datetime.now().isoformat()))\n",
    "\n",
    "        # Loop until the supervisor shuts down or 1000000 steps have completed.\n",
    "        step = 0\n",
    "        count = 0\n",
    "        while not sv.should_stop() and step < args.steps:\n",
    "        # Run a training step asynchronously.\n",
    "        # See `tf.train.SyncReplicasOptimizer` for additional details on how to\n",
    "        # perform *synchronous* training.\n",
    "\n",
    "            # using QueueRunners/Readers\n",
    "            if args.mode == \"train\":\n",
    "                #if (step % 100 == 0):\n",
    "                    #print(\"{0} step: {1} accuracy: {2}\".format(datetime.now().isoformat(), step, sess.run(accuracy)))\n",
    "                _, summary, step = sess.run([train_op, summary_op, global_step])\n",
    "                if sv.is_chief:\n",
    "                    summary_writer.add_summary(summary, step)\n",
    "        if task_index == 0:\n",
    "            time.sleep(60)\n",
    "\n",
    "        # Ask for all the services to stop.\n",
    "        print(\"{0} stopping supervisor\".format(datetime.now().isoformat()))\n",
    "        sv.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from hops import util\n",
    "from hops import hdfs\n",
    "import io\n",
    "\n",
    "from tensorflowonspark import TFCluster\n",
    "\n",
    "sc = spark.sparkContext\n",
    "num_executors = util.num_executors(spark)\n",
    "num_ps = util.num_param_servers(spark)\n",
    "\n",
    "model_location = \"hdfs:///Projects/colorizeML2/imagenet_vgg/vgg_model.npy\"\n",
    "model = sc.binaryFiles(model_location).map(lambda binaryData: binaryData[1]).map(lambda x: io.BytesIO(x)).map(lambda x: numpy.load(x)).take(1)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--epochs\", help=\"number of epochs\", type=int, default=0)\n",
    "parser.add_argument(\"-f\", \"--format\", help=\"example format: (csv|pickle|tfr)\", choices=[\"csv\",\"pickle\",\"tfr\"], default=\"csv\")\n",
    "parser.add_argument(\"-i\", \"--images\", help=\"HDFS path to MNIST images in parallelized format\", default='/Projects/' + hdfs.project_name() + '/imbd_face_dataset/processed')\n",
    "parser.add_argument(\"-l\", \"--labels\", help=\"HDFS path to MNIST labels in parallelized format\", default = '/Projects/' + hdfs.project_name() + '/mnist/train/labels')\n",
    "parser.add_argument(\"-m\", \"--model\", help=\"HDFS path to save/load model during train/test\", default=\"mnist_model\")\n",
    "parser.add_argument(\"-n\", \"--cluster_size\", help=\"number of nodes in the cluster (for Spark Standalone)\", type=int, default=num_executors)\n",
    "parser.add_argument(\"-o\", \"--output\", help=\"HDFS path to save test/inference output\", default=\"predictions\")\n",
    "parser.add_argument(\"-r\", \"--readers\", help=\"number of reader/enqueue threads\", type=int, default=1)\n",
    "parser.add_argument(\"-s\", \"--steps\", help=\"maximum number of steps\", type=int, default=4000000)\n",
    "parser.add_argument(\"-tb\", \"--tensorboard\", help=\"launch tensorboard process\", action=\"store_true\")\n",
    "parser.add_argument(\"-X\", \"--mode\", help=\"train|inference\", default=\"train\")\n",
    "parser.add_argument(\"-c\", \"--rdma\", help=\"use rdma connection\", default=False)\n",
    "parser.add_argument(\"-v\", \"--vgg\", default= model)\n",
    "args = parser.parse_args()\n",
    "print(\"args:\",args)\n",
    "\n",
    "print(\"{0} ===== Start\".format(datetime.now().isoformat()))\n",
    "\n",
    "cluster = TFCluster.run(sc, colorize_fun, args, args.cluster_size, num_ps, args.tensorboard, TFCluster.InputMode.TENSORFLOW)\n",
    "cluster.shutdown()\n",
    "\n",
    "print(\"{0} ===== Stop\".format(datetime.now().isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
